{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Team Jedi Hackathon","text":""},{"location":"index.html#overview","title":"Overview","text":"<p>This project allows developers to send a single channel sound file to a sound detection pipeline connected to business logic.  The business logic parses the inference results as data that is exported to InfluxDB, a time-series database. This time-series data can then be viewed on a Grafana dashboard and customized to send email notifications.</p> <ul> <li>Programming Languages: Python, Golang</li> <li>Technologies used : Docker, Docker Compose, Make, Conda, BentoML, Telegraf, InfluxDB, Grafana </li> <li>Intel OpenSource Technologies used: OpenVino, OpenVino Model Server (OVMS), EdgeX</li> </ul>"},{"location":"index.html#target-system-requirements","title":"Target System Requirements","text":"<ul> <li>Disk Space needed</li> </ul>"},{"location":"index.html#dependencies","title":"Dependencies:","text":"<ul> <li>Docker v24.0.0</li> <li>Docker Compose v2.17.3</li> <li>Golang v1.20</li> <li>Conda Environment with Python v3.8</li> <li>Sample Audio File - must be single channel and <code>.wav</code> format</li> </ul>"},{"location":"index.html#microservice-descriptions","title":"Microservice descriptions:","text":""},{"location":"index.html#bentoml-sound-detection-pipeline","title":"BentoML Sound Detection Pipeline","text":"<p>BentoML is a Unified Model Serving Framework which makes it easy to create ML-powered prediction services that are ready to deploy and scale. BentoML easily wraps the ML pipelines around web services. It is used by Data Scientists and ML Engineers to:</p> <ol> <li> <p>Accelerate and standardize the process of taking ML models to production</p> </li> <li> <p>Build scalable and high performance prediction services</p> </li> <li> <p>Continuously deploy, monitor, and operate prediction services in production</p> </li> </ol> <p>Learn more: BentoML</p> <p>Open Source Repository: GitHub</p> <p>Get Started on BentoML: Tutorial</p>"},{"location":"index.html#workflow","title":"Workflow","text":"<ol> <li> <p>Sound Classification Pipeline python example from the OpenVino Model Zoo is adopted and modified to build the ML pipeline for this use case.</p> </li> <li> <p>Bentos are created for this sound classification pipeline.</p> </li> <li> <p>BentoML is now used to build &amp; deploy these Bentos docker containers.</p> </li> <li> <p>These Bentos can be tested using the Swagger APIs. (Explained in detail below)</p> </li> <li> <p>This ML pipeline sends the following inference data to the business logic microservice -</p> <pre><code>{\n'timestamp': '2023-09-13 21:10:31.500582',\n'inputVideo': '${HOME}/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav', 'inference': [\n{\n'videoTimestamp': '[0.00-1.00]', 'label': 'Gunshot', 'accuracy': '100.00%'\n}, {\n'videoTimestamp': '[1.00-2.00]', 'label': 'Door knock', 'accuracy': '15.64%'\n}   ],\n'latency': 9.321213001385331\n}\n</code></pre> </li> </ol> ML Pipeline Service Development &amp; Deployment Workflow <p>More examples for developing with BentoML can be found here for the AiCSD project</p>"},{"location":"index.html#business-logic-application-service","title":"Business Logic Application Service","text":"<p>The microservice for the business logic is developed using the the golang-based Edgex app services. Sound Classification microservice sends POST request with the inference data to the business logic microservice. Here the inference results are stored in the InfluxDB which are then queried to display the results on the Grafana dashboard.</p>"},{"location":"index.html#how-it-works","title":"How It Works","text":"<p>Figure 1: Architecture Diagram</p> <p>In this project, a single-channel, wav-format sound file is sent over REST from the Swagger UI to the BentoML Sound Detection Pipeline container.  This container then calls OpenVino Model Server (OVMS) Docker container over gRPC to get the model status.  The Sound Detection Pipeline container will then run the Python inferencing and send the inference results over REST to the business logic application service. The business logic container is then responsible for parsing the inference results and persisting it to the InfluxDB. Initially it was discussed to create a separate data layer using EdgeX for persisting the data to influxDB. However, later decided to make direct call to InfluxDB from business logic microservice to keep it simple as adding additional microservice to this solution was an overhead. Ideally architecture should have separated these out, but complexity of setting up the data layer via EdgeX made us pivot to make direct calls to database. InfluxDB is responsible for storing the time-series data that is then visualized in a Grafana dashboard. The Grafana dashboard is configured for viewing inference results and sending email notifications.</p>"},{"location":"index.html#get-started","title":"Get Started","text":"<p>Provide step-by-step instructions for getting started.</p> <ol> <li>Install the listed dependencies.</li> <li> <p>Configure <code>DOCKER_INFLUXDB_INIT_PASSWORD</code> and <code>DOCKER_INFLUXDB_INIT_ADMIN_TOKEN</code> in the <code>.env</code> file for InfluxDB.</p> </li> <li> <p>Build the business logic container.     <pre><code>cd app-sample-service\nmake docker\ncd ..\n</code></pre></p> </li> <li> <p>Create a Conda working environment, configure it, and activate.     <pre><code>conda create -n hackathon_env python=3.8\nconda activate hackathon_env\ncd pipelines/sound_classification_demo\npip install -r requirements.txt\ncd ../..\n</code></pre></p> <p>Note</p> <p>Use <code>conda list</code> to verify all packages in requirements.txt are installed.</p> </li> <li> <p>Build the BentoML sound detection pipeline service     <pre><code>cd pipelines/sound_classification_demo\nmake build\n</code></pre></p> <p>Note</p> <p>To build and run the docker image, the build tag from the <code>make build</code> command is required.</p> <p>The following is the expected output from the build command:</p> <p></p> <p>Figure 2: BentoML Build Output</p> </li> <li> <p>[Optional] Build the BentoML Docker Image from the <code>pipelines/sound_classification_demo</code> directory.     <pre><code>make docker-build BENTO_TAG=&lt;bento_image_name&gt;:&lt;bento_image_tag&gt;\n</code></pre></p> <p>Note</p> <p>In the example above, the <code>BENTO_TAG</code> would be <code>BENTO_TAG=sound_classification:r5lystssnwbweb5w</code>.</p> </li> </ol>"},{"location":"index.html#run-the-application","title":"Run the Application","text":"<ol> <li>Configure the type of sound you want to get notified with.   Update the <code>docker-compose-apps.yml</code> line 18, and add sounds based on the file in here <code>models/aclnet-int8/aclnet_53cl.txt</code>  Each item must be in a comma separated:  <pre><code>SOUNDS: \"Gunshot,Door knock\"\n</code></pre></li> <li>Run the stack of services from the project root directory.     <pre><code>make run\n</code></pre> [Optional] Run Portainer for container management.  <pre><code>make run-portainer\n</code></pre></li> <li> <p>Start the BentoML service from the <code>pipelines/sound_classification_demo</code> directory.</p> Run Method Run Command Locally <code>make serve</code> Docker <code>make docker-run BENTO_TAG=&lt;bento_image_name&gt;:&lt;bento_image_tag&gt; PROJECT_REPO_PATH=&lt;project_repo_path&gt;</code> <p>Note</p> <p>In the example from setup, the <code>BENTO_TAG</code> would be <code>BENTO_TAG=sound_classification:r5lystssnwbweb5w</code>. The <code>PROJECT_REPO_PATH</code> is the full path to the <code>team-jedi-hackathon-dev</code> project.</p> </li> <li> <p>Open the Swagger API UI.</p> </li> <li> <p>Test a POST request to the <code>/classify</code> API by providing the input text as     <pre><code>{\n\"MediaPath\": \"${HOME}/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav\",\n\"ModelPath\": \"${HOME}/team-jedi-hackathon-dev/models/aclnet/1/aclnet_des_53.xml\",\n\"LabelPath\": \"${HOME}/team-jedi-hackathon-dev/models/aclnet/aclnet_53cl.txt\", \"GatewayIP\":\"XXX.XXX.X.X\", \"Port\":\"9001\"\n}\n</code></pre></p> <p>Success</p> <p>If the pipeline runs successfully, the Response Code will be 200 and the Response Body will look like <code>Success, inference_results: {'timestamp': '2023-09-13 21:10:31.500582', 'inputVideo': '${HOME}/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav', 'inference': [{'videoTimestamp': '[0.00-1.00]', 'label': 'Gunshot', 'accuracy': '100.00%'}, {'videoTimestamp': '[1.00-2.00]', 'label': 'Door knock', 'accuracy': '15.64%'}], 'latency': 9.321213001385331}</code></p> </li> <li> <p>To further verify the pipeline ran successfully, check the logs of the BentoML Pipeline container. The example below shows the logs from [Portainer][def]    Figure 3: Portainer container log screenshot</p> </li> <li> <p>Open influxDB to visualize data as well. Use <code>admin</code> as username and the password set inside the <code>.env</code> file.  Go to the dashboard section:    Import the file <code>telegraf/template.json</code>   Click on <code>Sound Dashboard</code>   Once in the dashboard, increase the refresh rate to 10s:  </p> </li> <li>Open the Grafana Dashboard to see the visualization of the inference results.</li> <li>To setup email notification in Grafana -</li> </ol> <p>a. open grafana dashboard - http://0.0.0.0:3001/grafana (log in as admin, password is admin)</p> <p>b. Go to Home/Alerting/Contact points</p> <p>c. Edit the default contact point name, edit option will appear only if logged in as admin</p> <p>d. Under addresses text box provide - alertgrafanaemail@gmail.com, gmail created for demo which is set in grafana.ini</p> <p>e. Click Test</p> <p>f. While clicking send test notification, following success message should be displayed - <code>Test Alert Sent</code> (need to be outside vpn)</p> <p>g. Now save the contact point.</p>"},{"location":"index.html#api-documentation","title":"API Documentation","text":"<ol> <li> <p>Sound Classification Pipeline - Python Microservice    POST http://0.0.0.0:3000/classify     <pre><code>{\n\"MediaPath\": \"${HOME}/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav\",\n\"ModelPath\": \"${HOME}/team-jedi-hackathon-dev/models/aclnet/1/aclnet_des_53.xml\",\n\"LabelPath\": \"${HOME}/team-jedi-hackathon-dev/models/aclnet/aclnet_53cl.txt\", \"GatewayIP\":\"XXX.XXX.X.X\", \"Port\":\"9001\"\n}\n</code></pre></p> <p>Success</p> <p>If the pipeline runs successfully, the Response Code will be 200 and the Response Body will look like <code>Success, inference_results: {'timestamp': '2023-09-13 21:10:31.500582', 'inputVideo': '${HOME}/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav', 'inference': [{'videoTimestamp': '[0.00-1.00]', 'label': 'Gunshot', 'accuracy': '100.00%'}, {'videoTimestamp': '[1.00-2.00]', 'label': 'Door knock', 'accuracy': '15.64%'}], 'latency': 9.321213001385331}</code></p> </li> <li> <p>Business Logic - Golang Microservice    <pre><code>  POST http://127.0.0.1:59741/api/v1/data\n  Payload:  {\"inference\": [{\"videoTimestamp\": \"[0.00-1.00]\", \"label\": \"Gunshot\", \"accuracy\": \"100.00%\"}, {\"videoTimestamp\": \"[1.00-2.00]\", \"label\": \"something\", \"accuracy\": \"15.64%\"}], \"latency\": 9.321213001385331}\n</code></pre>     If request is successfull, then the Response Code will be 200 </p> </li> </ol>"},{"location":"index.html#testing","title":"Testing","text":"<ol> <li>Unit test for golang microservices using <code>go test</code>.  <pre><code>    cd ${HOME}/team-jedi-hackathon-dev/app-sample-service\n    go test ./...\n</code></pre></li> <li>Python microservices can be unit tested using <code>pytest</code>.(TODO)</li> <li>Golang microservices can be integration tested using Postman by send a POST request  <pre><code>    POST http://127.0.0.1:59741/api/v1/data\n    Payload:  {\"inference\": [{\"videoTimestamp\": \"[0.00-1.00]\", \"label\": \"Gunshot\", \"accuracy\": \"100.00%\"}, {\"videoTimestamp\": \"[1.00-2.00]\", \"label\": \"something\", \"accuracy\": \"15.64%\"}], \"latency\": 9.321213001385331}\n</code></pre></li> <li> <p>Python AI/ML Pipelines can be integration tested using Swagger UI(steps explained above).</p> </li> <li> <p>Postman can also be used by sending a POST request  <pre><code>    POST http://0.0.0.0:3000/classify\n    Payload:  {\"MediaPath\": \"${HOME}/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav\", \"ModelPath\": \"${HOME}/team-jedi-hackathon-dev/models/aclnet/1/aclnet_des_53.xml\", \"LabelPath\": \"${HOME}/team-jedi-hackathon-dev/models/aclnet/aclnet_53cl.txt\", \"GatewayIP\":\"XXX.XXX.X.X\", \"Port\":\"9001\"}\n</code></pre></p> </li> <li>Check influxDB to test and visualize the data(steps explained above).</li> </ol>"},{"location":"index.html#summary-and-next-steps","title":"Summary and Next Steps","text":""},{"location":"index.html#final-solution","title":"Final Solution","text":"<p>This solutions aims to build an infrastructure for remote sensing, making it easy to integrate different AI/ML pipelines with minimal changes. Current solution supports a sound classification pipeline which raises an email alert notification when any sound perceived as a threat (e.g., gunshots, chainsaw etc.) is detected.</p>"},{"location":"index.html#solution-features","title":"Solution Features","text":"<ol> <li>Fully distributed solution achieved through microservices and containerization</li> <li>Faster development of application services using open-source framework EdgeX</li> <li>Seamless interaction between solution components written in different languages \u2013 Golang based Business microservices and Python based AI/ML pipelines</li> <li>Easily integrate a new AI/ML pipeline (e.g. Intel OpenVINO Model Zoo examples) as a microservice using open-source tool \u2013 BentoML</li> <li>Dashboard &amp; alert notifications added using open-source TIG stack \u2013 Telegraf, InfluxDB, Grafana</li> <li>Sound Classification pipeline executed using Intel OpenVINO and Intel OpenVINO Model Server (OVMS) serving model status.</li> <li>Security enabled via open-source framework EdgeX</li> </ol>"},{"location":"index.html#next-steps","title":"Next Steps","text":"<p>Following couldn't be finished due to lack of time -</p> <ol> <li>Pytest unit tests for Python microservices.</li> <li>Grafana email notification feature is integrated, however couldn't finish creating the Grafana rules to send email notification.</li> <li>Couldn't test the microservices with validation service.</li> <li>Infer sound using Intel OVMS instead of Intel OpenVINO, contacted OVMS team for help.</li> </ol>"},{"location":"index.html#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>While building the Sound Classification pipeline microservices using BentoMl, several package dependecy issues can be resolved by using conda environment. Make sure all packages are installed before building &amp; running them.</p> </li> <li> <p>Sound Classification pipeline from OpenVINO model zoo didn't work initially. Raised issue using github to get support on the same from the OpenVINO team.</p> </li> <li> <p>Access Grafana Dashboard using this link - http://0.0.0.0:3001/grafana. Accessing the link directly from portainer (http://0.0.0.0:3001) results in error as it doesn't append grafana to the link.</p> </li> <li> <p>For setting up the Grafana email notifications, user need to log in as admin.</p> </li> </ol>"},{"location":"Hackathon_documentation_template.html","title":"Name of Product","text":""},{"location":"Hackathon_documentation_template.html#overview","title":"Overview","text":"<p>Provide a 2-3 line description of what this product allows the developer to do. </p> <p>NOTE: Keep this section easy to understand. Make it easy for users to understand what the input and output is.</p> <ul> <li>Programming Language: </li> <li>Technologies used : <p>NOTE: List the technologies, frameworks, libraries, and tools you utilized in your microservices project</p> </li> </ul>"},{"location":"Hackathon_documentation_template.html#target-system-requirements","title":"Target System Requirements","text":"<ul> <li>Disk Space needed </li> <li>Other Requirements </li> </ul>"},{"location":"Hackathon_documentation_template.html#microservice-descriptions","title":"Microservice descriptions:","text":"<p>NOTE:  1. Discuss the interactions between any other microservices and how they communicate (e.g., RESTful APIs, message queues).  2. Describe how data is stored, managed, and shared</p>"},{"location":"Hackathon_documentation_template.html#how-it-works","title":"How It Works","text":"<p>NOTE: Provide description, including architecture diagram, of how the product works. All diagrams and screenshots must have alt-text and captions.</p> <p>![Add alt-text description of image here.] (images/my-arch-diagram.png)</p> <p>Figure 1: Architecture Diagram  </p>"},{"location":"Hackathon_documentation_template.html#get-started","title":"Get Started","text":"<p>Provide step-by-step instructions for getting started.</p> <p>NOTE: Keep these easy to run. Avoid coding and manual configurations after installation. The input, or the configuration of the input, must be included in the package.</p> <ol> <li> <p>Text.</p> </li> <li> <p>Text with code.</p> </li> </ol> <pre><code>code snippet\n</code></pre> <ol> <li>Text with filepath. Go to the <code>name</code> directory.</li> </ol> <pre><code>cd name /\n</code></pre> <ol> <li>Text with code and screenshot.</li> </ol> <pre><code>code snippet\n</code></pre> <p>You will see output similar to the following:</p> <p></p> <p>Figure 2: Product Dashboard</p>"},{"location":"Hackathon_documentation_template.html#run-the-application","title":"Run the Application","text":"<p>Provide detailed steps for running the application. </p> <ol> <li> <p>Text.</p> </li> <li> <p>Text with code.</p> </li> </ol> <pre><code>code snippet\n</code></pre>"},{"location":"Hackathon_documentation_template.html#api-documentation","title":"API Documentation","text":"<p>If your microservices expose APIs, document each API endpoint, including its purpose, input parameters, expected output, and any authentication/authorization requirements. Provide sample API requests and responses for clarity.</p>"},{"location":"Hackathon_documentation_template.html#testing","title":"Testing","text":"<p>Discuss the testing approach you followed for your microservices. Document unit tests, integration tests, and any other types of tests performed. Include instructions on how to run the tests.</p>"},{"location":"Hackathon_documentation_template.html#summary-and-next-steps","title":"Summary and Next Steps","text":"<p>Note: Provide 2-3 line description of what the user has successfully done and where they should go to as the next step. </p>"},{"location":"Hackathon_documentation_template.html#troubleshooting","title":"Troubleshooting","text":"<p>Include a section addressing common issues, error handling, and troubleshooting tips.</p>"}]}